<!DOCTYPE html>
<!--
 | Generated by Apache Maven Doxia Site Renderer 1.8.1 from src/site/markdown/index.md at 2018-10-15
 | Rendered using Apache Maven Fluido Skin 1.7
-->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="Date-Revision-yyyymmdd" content="20181015" />
    <meta http-equiv="Content-Language" content="en" />
    <title>HA : 3-node active active + DR - Application &#x2013; HA : 3-node active active with disaster recovery</title>
    <link rel="stylesheet" href="./css/apache-maven-fluido-1.7.min.css" />
    <link rel="stylesheet" href="./css/site.css" />
    <link rel="stylesheet" href="./css/print.css" media="print" />
    <script type="text/javascript" src="./js/apache-maven-fluido-1.7.min.js"></script>
  </head>
  <body class="topBarDisabled">
    <div class="container-fluid">
      <div id="banner">
        <div class="pull-left"><div id="bannerLeft"><h2>HA : 3-node active active + DR - Application</h2>
</div>
</div>
        <div class="pull-right"></div>
        <div class="clear"><hr/></div>
      </div>

      <div id="breadcrumbs">
        <ul class="breadcrumb">
        <li id="publishDate">Last Published: 2018-10-15<span class="divider">|</span>
</li>
          <li id="projectVersion">Version: 1.0.0</li>
        </ul>
      </div>
      <div class="row-fluid">
        <div id="leftColumn" class="span2">
          <div class="well sidebar-nav">
    <ul class="nav nav-list">
      <li class="nav-header">Overview</li>
    <li class="active"><a href="#"><span class="none"></span>Introduction</a></li>
    <li><a href="using.html" title="Using"><span class="none"></span>Using</a></li>
      <li class="nav-header">Project Documentation</li>
    <li><a href="project-info.html" title="Project Information"><span class="icon-chevron-right"></span>Project Information</a></li>
</ul>
          <hr />
          <div id="poweredBy">
            <div class="clear"></div>
            <div class="clear"></div>
            <div class="clear"></div>
            <div class="clear"></div>
<a href="http://maven.apache.org/" title="Built by Maven" class="poweredBy"><img class="builtBy" alt="Built by Maven" src="./images/logos/maven-feather.png" /></a>
            </div>
          </div>
        </div>
        <div id="bodyColumn"  class="span10" >
<h1>HA : 3-node active active with disaster recovery</h1>
<p>This sample describes how to deploy an EventFlow fragment in a 3-node active active configuration with disaster recovery</p>
<ul>

<li><a href="#machines-and-nodes">Machines and nodes</a></li>
<li><a href="#data-partitioning">Data partitioning</a></li>
<li><a href="#define-the-application-definition-configuration">Define the application definition configuration</a></li>
<li><a href="#define-the-node-deployment-configuration">Define the node deployment configuration</a></li>
<li><a href="#design-notes">Design notes</a></li>
<li><a href="#failure-scenarios">Failure scenarios</a></li>
<li><a href="#building-this-sample-from-the-command-line-and-running-the-integration-test-cases">Building this sample from the command line and running the integration test cases</a></li>
</ul>
<div class="section">
<h2><a name="Machines_and_nodes"></a>Machines and nodes</h2>
<p>In this sample we name the machines as <b>A</b>,  which hosts the StreamBase node <b>A</b>, <b>B</b>, which hosts the StreamBase node <b>B</b> and <b>C</b> which hosts StreamBase node <b>C</b>. We also have disaster recovery machine <b>D</b> which hosts the StreamBase node <b>D</b> - this can be situated offsite and connected to the main machines via a wide area network :</p>
<p><img src="images/three-node-active-active-dr-nodes.svg" alt="nodes" /></p>
<p>A client that uses the service can connect to any of the main data center machines.</p>
<p>( service names are omitted in descriptions for clarity )</p></div>
<div class="section">
<h2><a name="Data_partitioning"></a>Data partitioning</h2>
<p>In this sample the default <b>default-cluster-wide-availability-zone</b> is used to distribute the data across all the nodes - a number of virtual partitions are created to evenly balance and replicate data around the cluster.  The disaster recovery node <b>D</b> is configured as a <b>BACKUP</b> type so that it is a replica for all data - asynchronous replication is used across the wide are network to avoid impacts due to network latency :</p>
<p><img src="images/three-node-active-active-dr-partitions.svg" alt="partitions" /></p>
<p>( only 3 virtual partitions are shown - the default is 64 )</p></div>
<div class="section">
<h2><a name="Define_the_application_definition_configuration"></a>Define the application definition configuration</h2>
<p>In this sample we want to use <b>asynchronous</b> replication for the disaster recovery machine, so we need to specify this in the application definition :</p>

<div>
<div>
<pre class="source">name = &quot;aa-3node-dr-app&quot;
version = &quot;1.0.0&quot;
type = &quot;com.tibco.ep.dtm.configuration.application&quot;

configuration = {
    ApplicationDefinition = {
        execution {
            nodeTypes {
                docker {
                    sharedMemory = {
                        memoryType = SYSTEM_V_SHARED_MEMORY
                    }
                }
            }
        }     
        dataDistributionPolicies = {
            default-dynamic-data-distribution-policy = {
                type = &quot;DYNAMIC&quot;                
                dynamicDataDistributionPolicy = {
                    primaryDataRedundancy = {
                        replicationType = &quot;SYNCHRONOUS&quot;
                    }
                    backupDataRedundancy = {
                        replicationType = &quot;ASYNCHRONOUS&quot;
                    }
                }                                       
            }
            main-data-center-policy = {
                type = &quot;STATIC&quot;                                                      
            }      
        }
    }
}
</pre></div></div>
</div>
<div class="section">
<h2><a name="Define_the_node_deployment_configuration"></a>Define the node deployment configuration</h2>
<p>For this sample we set the dynamic partition binding type of node <b>D</b> to <b>BACKUP</b> and the main data center nodes to <b>PRIMARY</b>.  Also,  we need to override the default value of <b>primaryMemberPattern</b>.  The <b>minimumNumberOfVotes</b> configuration enables quorums for the main data center, so the node deployment configuration is :</p>

<div>
<div>
<pre class="source">name = &quot;aa-3node-dr-app&quot;
version = &quot;1.0.0&quot;
type = &quot;com.tibco.ep.dtm.configuration.node&quot;

configuration = {
    NodeDeploy = {
        nodes = {
            &quot;A.aa-3node-dr-app&quot; = {
                engines = {
                    aa-3node-dr-ef = {
                        fragmentIdentifier = &quot;com.tibco.ep.samples.highavailability.aa-3node-dr-ef&quot;                                                                
                    }                                                    
                }
                availabilityZoneMemberships = {
                    default-cluster-wide-availability-zone = {
                        dynamicPartitionBinding = {
                            type = &quot;PRIMARY&quot;                                                                           
                        }
                    }
                    main-data-center-availability-zone = {                                                              
                    }
                }
            }
            &quot;B.aa-3node-dr-app&quot; = {
                engines = {
                    aa-3node-dr-ef = {
                        fragmentIdentifier = &quot;com.tibco.ep.samples.highavailability.aa-3node-dr-ef&quot;                                                                
                    }                                                    
                }
                availabilityZoneMemberships = {
                    default-cluster-wide-availability-zone = {
                        dynamicPartitionBinding = {
                            type = &quot;PRIMARY&quot;                                                                           
                        }
                    }
                    main-data-center-availability-zone = {                                                              
                    }
                }
            }
            &quot;C.aa-3node-dr-app&quot; = {
                engines = {
                    aa-3node-dr-ef = {
                        fragmentIdentifier = &quot;com.tibco.ep.samples.highavailability.aa-3node-dr-ef&quot;                                                                
                    }                                                    
                }
                availabilityZoneMemberships = {
                    default-cluster-wide-availability-zone = {
                        dynamicPartitionBinding = {
                            type = &quot;PRIMARY&quot;                                                                           
                        }
                    }
                    main-data-center-availability-zone = {                                                              
                    }
                }
            }
            &quot;D.aa-3node-dr-app&quot; = {
                engines = {
                    aa-3node-dr-ef = {
                        fragmentIdentifier = &quot;com.tibco.ep.samples.highavailability.aa-3node-dr-ef&quot;                                                                
                    }                                                    
                }
                availabilityZoneMemberships = {
                    default-cluster-wide-availability-zone = {
                        dynamicPartitionBinding = {
                            type = &quot;BACKUP&quot;                                                                           
                        }
                    }
                }
            }      
        }
        availabilityZones = {
            main-data-center-availability-zone = {
                dataDistributionPolicy = &quot;main-data-center-policy&quot;
                // enable quorums - each node must be able to see itself plus 1 other node
                //
                minimumNumberOfVotes = 2
            }
            default-cluster-wide-availability-zone = {
                dataDistributionPolicy = &quot;default-dynamic-data-distribution-policy&quot;
                // disable auto adding all nodes as primary
                //
                dynamicPartitionPolicy = {
                    primaryMemberPattern = &quot;&quot;                                                  
                }
            }
        }
    }
}
</pre></div></div>

<p>Note that <b>percentageOfVotes</b> could be used instead.  An alternative configuration for quorums could use <b>quorumMemberPattern</b>.</p></div>
<div class="section">
<h2><a name="Design_notes"></a>Design notes</h2>
<ul>

<li>The default dynamic data distribution policy is chosen to distribute the data across the cluster</li>
<li>An addition data distribution policy and availability zone is used to hold the quorum configuration for the main data center</li>
<li>Most of the data distribution policy and the availability zone configuration values are not set since defaults work well</li>
</ul></div>
<div class="section">
<h2><a name="Failure_scenarios"></a>Failure scenarios</h2>
<p>The main failure cases for this deployment are outlined below :</p>
<table border="0" class="table table-striped">
<thead>

<tr class="a">
<th>Failure case   </th>
<th> Behaviour on failure </th>
<th> Steps to resolve </th>
<th> Notes</th></tr>
</thead><tbody>

<tr class="b">
<td>Machine A fails </td>
<td> 1 Client is disconnected<br />2 Virtual partitions become active on B &amp; C<br />3 Client may connect to B or C and continue  </td>
<td> 1 Fix machine A<br />2 Use <b>epadmin install node</b> and <b>epadmin start node</b> </td>
<td> 1 No data loss<br />2 No service loss</td></tr>
<tr class="a">
<td>Machine B fails </td>
<td> 1 Client is disconnected<br />2 Virtual partitions become active on A &amp; C<br />3 Client may connect to A or C and continue  </td>
<td> 1 Fix machine B<br />2 Use <b>epadmin install node</b> and <b>epadmin start node</b> </td>
<td> 1 No data loss<br />2 No service loss</td></tr>
<tr class="b">
<td>Machine C fails </td>
<td> 1 Client is disconnected<br />2 Virtual partitions become active on A &amp; B<br />3 Client may connect to A or B and continue  </td>
<td> 1 Fix machine C<br />2 Use <b>epadmin install node</b> and <b>epadmin start node</b> </td>
<td> 1 No data loss<br />2 No service loss<br /></td></tr>
<tr class="a">
<td>Machine D fails </td>
<td> 1 Disaster recover facility is lost </td>
<td> 1 Fix machine D<br />2 Use <b>epadmin install node</b> and <b>epadmin start node</b> </td>
<td> 1 No data loss<br />2 No service loss</td></tr>
<tr class="b">
<td>Main data center loss </td>
<td> 1 All clients are disconnected<br />2 Virtual partitions become active on D </td>
<td> 1 Fix data center<br />2 Use <b>epadmin install node</b> and <b>epadmin start node</b> </td>
<td> 1 No data loss<br />2 <b>Temporary service loss</b></td></tr>
<tr class="a">
<td>Network fails to A </td>
<td> 1 Quorum on A fails and takes itself offline to avoid multi-master </td>
<td> 1 Fix network<br />2 Use <b>epadmin restore availabilityzone</b> </td>
<td> 1 No data loss<br />2 No service loss</td></tr>
<tr class="b">
<td>Network fails to B </td>
<td> 1 Quorum on B fails and takes itself offline to avoid multi-master </td>
<td> 1 Fix network<br />2 Use <b>epadmin restore availabilityzone</b> </td>
<td> 1 No data loss<br />2 No service loss</td></tr>
<tr class="a">
<td>Network fails to C </td>
<td> 1 Quorum on C fails and takes itself offline to avoid multi-master </td>
<td> 1 Fix network<br />2 Use <b>epadmin restore availabilityzone</b> </td>
<td> 1 No data loss<br />2 No service loss</td></tr>
</tbody>
</table>
<p>With a 3 node configuration node quorums can be applied to avoid a multi-master scenario.</p></div>
<div class="section">
<h2><a name="Building_this_sample_from_the_command_line_and_running_the_integration_test_cases"></a>Building this sample from the command line and running the integration test cases</h2>
<p>In this sample, some HA integration test cases are defined in the pom.xml that :</p>
<ul>

<li>start nodes A, B, C &amp; D</li>
<li>use <b>epadmin start playback</b> to inject tuples to node A</li>
<li>use <b>epadmin read querytable</b> on node A to verify query table contents</li>
<li>stop nodes A, B &amp; C</li>
<li>use <b>epadmin read querytable</b> on node D to verify no data loss</li>
<li>stop node D</li>
</ul>
<p>:warning: This does not constitute an exhaustive non-functional test plan</p>
<p>Use the <a class="externalLink" href="https://maven.apache.org">maven</a> as <b>mvn install</b> to build from the command line or Continuous Integration system :</p>
<p><img src="images/maven.gif" alt="maven" /></p></div>
        </div>
      </div>
    </div>
    <hr/>
    <footer>
      <div class="container-fluid">
        <div class="row-fluid">
            <p>Copyright &copy;2018
<a href="http://www.tibco.com">TIBCO Software Inc.</a>.
All rights reserved.</p>
        </div>
      </div>
    </footer>
  </body>
</html>
